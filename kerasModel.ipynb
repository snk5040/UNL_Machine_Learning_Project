{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow.keras\n",
    "import autokeras as ak\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Input Data: (3000, 1776)\n",
      "Shape of Test Labels: (751,)\n"
     ]
    }
   ],
   "source": [
    "# Load training dataset\n",
    "df1 = pd.read_csv('./bioresponse/train.csv')\n",
    "#df1['Activity'] = df1['Activity'].apply(np.int64)\n",
    "#display(df1['Activity'].dtypes) \n",
    "#df1.describe() # Visualize\n",
    "\n",
    "# Load testing dataset\n",
    "kaggle_test = pd.read_csv('./bioresponse/test.csv')\n",
    "# test.describe() # Visualize\n",
    "\n",
    "# Separate labels from training dataset for fitting\n",
    "labels = df1['Activity']\n",
    "del df1['Activity']\n",
    "\n",
    "# 80/20 train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df1, labels, test_size=0.2)\n",
    "input_shape = x_train.shape\n",
    "print(\"Shape of Input Data: \" + str(input_shape))\n",
    "print(\"Shape of Test Labels: \" + str(y_test.shape))\n",
    "\n",
    "#print(labels.describe())\n",
    "#display(y_train.dtypes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 200)               355400    \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 32)                3232      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 378765 (1.44 MB)\n",
      "Trainable params: 378765 (1.44 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(200, input_dim=x_train.shape[1], activation='relu'))\n",
    "#model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "#model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "#model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "#model.add(layers.Softmax())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 0.4940 - accuracy: 0.7880 - val_loss: 0.6327 - val_accuracy: 0.7603\n",
      "Epoch 2/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.5133 - accuracy: 0.7850 - val_loss: 0.6449 - val_accuracy: 0.7417\n",
      "Epoch 3/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.4955 - accuracy: 0.7973 - val_loss: 0.6104 - val_accuracy: 0.7537\n",
      "Epoch 4/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.5751 - accuracy: 0.7717 - val_loss: 1.3076 - val_accuracy: 0.6897\n",
      "Epoch 5/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.5776 - accuracy: 0.7827 - val_loss: 0.9349 - val_accuracy: 0.6684\n",
      "Epoch 6/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.6953 - accuracy: 0.7540 - val_loss: 0.6378 - val_accuracy: 0.7656\n",
      "Epoch 7/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.7021 - accuracy: 0.7730 - val_loss: 0.9663 - val_accuracy: 0.6724\n",
      "Epoch 8/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.6731 - accuracy: 0.7727 - val_loss: 2.3793 - val_accuracy: 0.5140\n",
      "Epoch 9/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.6971 - accuracy: 0.7683 - val_loss: 0.6695 - val_accuracy: 0.7870\n",
      "Epoch 10/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.7630 - accuracy: 0.7647 - val_loss: 1.2563 - val_accuracy: 0.6684\n",
      "Epoch 11/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 1.0795 - accuracy: 0.7300 - val_loss: 2.3524 - val_accuracy: 0.6471\n",
      "Epoch 12/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 1.1648 - accuracy: 0.7300 - val_loss: 1.4544 - val_accuracy: 0.6644\n",
      "Epoch 13/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 1.1446 - accuracy: 0.7347 - val_loss: 3.4645 - val_accuracy: 0.6631\n",
      "Epoch 14/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 2.8536 - accuracy: 0.6823 - val_loss: 1.8440 - val_accuracy: 0.6818\n",
      "Epoch 15/200\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 1.9762 - accuracy: 0.7023 - val_loss: 2.5312 - val_accuracy: 0.6471\n",
      "Epoch 16/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 3.6832 - accuracy: 0.6550 - val_loss: 2.0389 - val_accuracy: 0.7017\n",
      "Epoch 17/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 2.4140 - accuracy: 0.7087 - val_loss: 3.1908 - val_accuracy: 0.6804\n",
      "Epoch 18/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 2.1070 - accuracy: 0.7140 - val_loss: 2.6295 - val_accuracy: 0.6565\n",
      "Epoch 19/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 3.3918 - accuracy: 0.6837 - val_loss: 5.1237 - val_accuracy: 0.6578\n",
      "Epoch 20/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 6.1757 - accuracy: 0.6437 - val_loss: 14.4517 - val_accuracy: 0.6565\n",
      "Epoch 21/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 7.5800 - accuracy: 0.6680 - val_loss: 7.8021 - val_accuracy: 0.6005\n",
      "Epoch 22/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 8.3331 - accuracy: 0.6533 - val_loss: 17.3171 - val_accuracy: 0.4820\n",
      "Epoch 23/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 5.5488 - accuracy: 0.6883 - val_loss: 4.4046 - val_accuracy: 0.7004\n",
      "Epoch 24/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 4.5534 - accuracy: 0.7260 - val_loss: 6.9303 - val_accuracy: 0.6391\n",
      "Epoch 25/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 10.0580 - accuracy: 0.6340 - val_loss: 12.1117 - val_accuracy: 0.6059\n",
      "Epoch 26/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 10.1874 - accuracy: 0.6503 - val_loss: 22.6559 - val_accuracy: 0.4860\n",
      "Epoch 27/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 9.6313 - accuracy: 0.6743 - val_loss: 12.3620 - val_accuracy: 0.5726\n",
      "Epoch 28/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 9.8295 - accuracy: 0.6673 - val_loss: 13.8077 - val_accuracy: 0.5965\n",
      "Epoch 29/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 11.3012 - accuracy: 0.6587 - val_loss: 9.7505 - val_accuracy: 0.6045\n",
      "Epoch 30/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 10.9955 - accuracy: 0.6487 - val_loss: 11.4917 - val_accuracy: 0.5939\n",
      "Epoch 31/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 13.1976 - accuracy: 0.6607 - val_loss: 10.2136 - val_accuracy: 0.6538\n",
      "Epoch 32/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 21.3868 - accuracy: 0.6000 - val_loss: 13.2965 - val_accuracy: 0.6298\n",
      "Epoch 33/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 22.1388 - accuracy: 0.6060 - val_loss: 27.9613 - val_accuracy: 0.5166\n",
      "Epoch 34/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 19.5877 - accuracy: 0.6277 - val_loss: 24.5461 - val_accuracy: 0.6658\n",
      "Epoch 35/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 24.5539 - accuracy: 0.6220 - val_loss: 39.9351 - val_accuracy: 0.5686\n",
      "Epoch 36/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 26.0026 - accuracy: 0.6207 - val_loss: 48.8312 - val_accuracy: 0.4807\n",
      "Epoch 37/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 46.5583 - accuracy: 0.5860 - val_loss: 24.5719 - val_accuracy: 0.5832\n",
      "Epoch 38/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 37.3524 - accuracy: 0.5970 - val_loss: 15.6003 - val_accuracy: 0.6165\n",
      "Epoch 39/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 30.1110 - accuracy: 0.6120 - val_loss: 37.7641 - val_accuracy: 0.5113\n",
      "Epoch 40/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 42.7443 - accuracy: 0.5890 - val_loss: 18.3194 - val_accuracy: 0.6365\n",
      "Epoch 41/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 30.4883 - accuracy: 0.6113 - val_loss: 15.7796 - val_accuracy: 0.6085\n",
      "Epoch 42/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 38.3117 - accuracy: 0.6013 - val_loss: 40.1445 - val_accuracy: 0.5766\n",
      "Epoch 43/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 48.2489 - accuracy: 0.5727 - val_loss: 72.7532 - val_accuracy: 0.5593\n",
      "Epoch 44/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 66.6248 - accuracy: 0.5693 - val_loss: 53.0128 - val_accuracy: 0.5632\n",
      "Epoch 45/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 63.5867 - accuracy: 0.5720 - val_loss: 23.0394 - val_accuracy: 0.6298\n",
      "Epoch 46/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 83.8495 - accuracy: 0.5743 - val_loss: 81.2575 - val_accuracy: 0.5859\n",
      "Epoch 47/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 51.4756 - accuracy: 0.6043 - val_loss: 62.7728 - val_accuracy: 0.6112\n",
      "Epoch 48/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 71.0605 - accuracy: 0.5970 - val_loss: 89.3755 - val_accuracy: 0.4834\n",
      "Epoch 49/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 129.7747 - accuracy: 0.5533 - val_loss: 309.9409 - val_accuracy: 0.4607\n",
      "Epoch 50/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 69.3295 - accuracy: 0.6123 - val_loss: 30.5968 - val_accuracy: 0.6405\n",
      "Epoch 51/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 75.9499 - accuracy: 0.5837 - val_loss: 90.0462 - val_accuracy: 0.6245\n",
      "Epoch 52/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 60.5588 - accuracy: 0.5977 - val_loss: 74.0618 - val_accuracy: 0.5419\n",
      "Epoch 53/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 77.8071 - accuracy: 0.5640 - val_loss: 46.9932 - val_accuracy: 0.5846\n",
      "Epoch 54/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 100.9024 - accuracy: 0.5770 - val_loss: 83.5101 - val_accuracy: 0.4754\n",
      "Epoch 55/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 119.3384 - accuracy: 0.5603 - val_loss: 103.2630 - val_accuracy: 0.5819\n",
      "Epoch 56/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 110.0704 - accuracy: 0.5730 - val_loss: 106.3866 - val_accuracy: 0.5885\n",
      "Epoch 57/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 94.5493 - accuracy: 0.5790 - val_loss: 113.8989 - val_accuracy: 0.5566\n",
      "Epoch 58/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 147.3873 - accuracy: 0.5547 - val_loss: 90.2220 - val_accuracy: 0.5992\n",
      "Epoch 59/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 150.3988 - accuracy: 0.5787 - val_loss: 172.1987 - val_accuracy: 0.5140\n",
      "Epoch 60/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 119.1905 - accuracy: 0.5820 - val_loss: 112.3379 - val_accuracy: 0.5233\n",
      "Epoch 61/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 345.6389 - accuracy: 0.5280 - val_loss: 204.2079 - val_accuracy: 0.5419\n",
      "Epoch 62/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 99.5871 - accuracy: 0.5920 - val_loss: 106.9964 - val_accuracy: 0.5872\n",
      "Epoch 63/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 235.2870 - accuracy: 0.5283 - val_loss: 70.9868 - val_accuracy: 0.5939\n",
      "Epoch 64/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 187.2838 - accuracy: 0.5657 - val_loss: 80.9514 - val_accuracy: 0.5686\n",
      "Epoch 65/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 139.6408 - accuracy: 0.5840 - val_loss: 160.3622 - val_accuracy: 0.5752\n",
      "Epoch 66/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 189.6669 - accuracy: 0.5793 - val_loss: 165.1406 - val_accuracy: 0.5353\n",
      "Epoch 67/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 222.8733 - accuracy: 0.5630 - val_loss: 289.5790 - val_accuracy: 0.5579\n",
      "Epoch 68/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 246.7427 - accuracy: 0.5543 - val_loss: 378.9175 - val_accuracy: 0.5126\n",
      "Epoch 69/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 250.7141 - accuracy: 0.5690 - val_loss: 144.2500 - val_accuracy: 0.5672\n",
      "Epoch 70/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 237.6746 - accuracy: 0.5790 - val_loss: 106.5294 - val_accuracy: 0.6258\n",
      "Epoch 71/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 242.0895 - accuracy: 0.5687 - val_loss: 170.1754 - val_accuracy: 0.4953\n",
      "Epoch 72/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 326.0103 - accuracy: 0.5650 - val_loss: 201.7362 - val_accuracy: 0.5699\n",
      "Epoch 73/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 172.2011 - accuracy: 0.6067 - val_loss: 103.2711 - val_accuracy: 0.5965\n",
      "Epoch 74/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 301.8992 - accuracy: 0.5557 - val_loss: 394.7541 - val_accuracy: 0.5007\n",
      "Epoch 75/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 188.0288 - accuracy: 0.5993 - val_loss: 103.1385 - val_accuracy: 0.5752\n",
      "Epoch 76/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 291.1642 - accuracy: 0.5637 - val_loss: 699.0198 - val_accuracy: 0.5513\n",
      "Epoch 77/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 383.0806 - accuracy: 0.5517 - val_loss: 238.2685 - val_accuracy: 0.5446\n",
      "Epoch 78/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 202.0305 - accuracy: 0.5867 - val_loss: 79.8237 - val_accuracy: 0.6205\n",
      "Epoch 79/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 399.0125 - accuracy: 0.5530 - val_loss: 1039.1306 - val_accuracy: 0.5007\n",
      "Epoch 80/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 329.9271 - accuracy: 0.5727 - val_loss: 336.9637 - val_accuracy: 0.5499\n",
      "Epoch 81/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 387.9457 - accuracy: 0.5727 - val_loss: 1082.9446 - val_accuracy: 0.4754\n",
      "Epoch 82/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 500.8865 - accuracy: 0.5653 - val_loss: 248.9665 - val_accuracy: 0.5699\n",
      "Epoch 83/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 425.0503 - accuracy: 0.5420 - val_loss: 178.6460 - val_accuracy: 0.5925\n",
      "Epoch 84/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 243.9075 - accuracy: 0.5950 - val_loss: 630.1296 - val_accuracy: 0.5566\n",
      "Epoch 85/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 263.3908 - accuracy: 0.5910 - val_loss: 258.3064 - val_accuracy: 0.6471\n",
      "Epoch 86/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 430.6015 - accuracy: 0.5670 - val_loss: 730.1953 - val_accuracy: 0.5513\n",
      "Epoch 87/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 650.5743 - accuracy: 0.5590 - val_loss: 692.4946 - val_accuracy: 0.6005\n",
      "Epoch 88/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 503.7009 - accuracy: 0.5800 - val_loss: 620.5870 - val_accuracy: 0.5952\n",
      "Epoch 89/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 679.0310 - accuracy: 0.5577 - val_loss: 907.9502 - val_accuracy: 0.6032\n",
      "Epoch 90/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 369.1293 - accuracy: 0.5747 - val_loss: 383.2258 - val_accuracy: 0.5686\n",
      "Epoch 91/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 396.6160 - accuracy: 0.5813 - val_loss: 1050.9778 - val_accuracy: 0.4421\n",
      "Epoch 92/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 657.7876 - accuracy: 0.5597 - val_loss: 381.2750 - val_accuracy: 0.5686\n",
      "Epoch 93/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 436.9837 - accuracy: 0.5883 - val_loss: 245.7221 - val_accuracy: 0.5965\n",
      "Epoch 94/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 627.7371 - accuracy: 0.5563 - val_loss: 1552.8844 - val_accuracy: 0.5712\n",
      "Epoch 95/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 565.6974 - accuracy: 0.5740 - val_loss: 487.7757 - val_accuracy: 0.4874\n",
      "Epoch 96/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 445.0491 - accuracy: 0.5673 - val_loss: 481.4246 - val_accuracy: 0.5632\n",
      "Epoch 97/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 490.1222 - accuracy: 0.6023 - val_loss: 618.9044 - val_accuracy: 0.5606\n",
      "Epoch 98/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 718.6122 - accuracy: 0.5703 - val_loss: 181.6712 - val_accuracy: 0.6724\n",
      "Epoch 99/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 525.5559 - accuracy: 0.5863 - val_loss: 251.7554 - val_accuracy: 0.5806\n",
      "Epoch 100/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 428.8990 - accuracy: 0.5747 - val_loss: 326.5619 - val_accuracy: 0.5632\n",
      "Epoch 101/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 572.8136 - accuracy: 0.5710 - val_loss: 1134.3616 - val_accuracy: 0.5619\n",
      "Epoch 102/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 500.7504 - accuracy: 0.5993 - val_loss: 449.0070 - val_accuracy: 0.5925\n",
      "Epoch 103/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 471.7459 - accuracy: 0.5873 - val_loss: 957.2554 - val_accuracy: 0.5113\n",
      "Epoch 104/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 600.7145 - accuracy: 0.5963 - val_loss: 349.8418 - val_accuracy: 0.6045\n",
      "Epoch 105/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 490.7507 - accuracy: 0.6047 - val_loss: 209.3509 - val_accuracy: 0.6152\n",
      "Epoch 106/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1097.5289 - accuracy: 0.5563 - val_loss: 1163.2478 - val_accuracy: 0.6099\n",
      "Epoch 107/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 628.7795 - accuracy: 0.5850 - val_loss: 682.3711 - val_accuracy: 0.6298\n",
      "Epoch 108/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 463.7418 - accuracy: 0.6097 - val_loss: 755.4785 - val_accuracy: 0.6099\n",
      "Epoch 109/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 644.0367 - accuracy: 0.5917 - val_loss: 706.4305 - val_accuracy: 0.5912\n",
      "Epoch 110/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 665.0743 - accuracy: 0.5840 - val_loss: 758.8602 - val_accuracy: 0.5659\n",
      "Epoch 111/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 709.1301 - accuracy: 0.5940 - val_loss: 845.8638 - val_accuracy: 0.5672\n",
      "Epoch 112/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 945.2096 - accuracy: 0.5727 - val_loss: 1273.2969 - val_accuracy: 0.4834\n",
      "Epoch 113/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 672.9166 - accuracy: 0.6003 - val_loss: 465.6004 - val_accuracy: 0.5632\n",
      "Epoch 114/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1416.0460 - accuracy: 0.5527 - val_loss: 1590.9471 - val_accuracy: 0.4621\n",
      "Epoch 115/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 742.3519 - accuracy: 0.5890 - val_loss: 562.5535 - val_accuracy: 0.6485\n",
      "Epoch 116/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 431.8443 - accuracy: 0.6253 - val_loss: 318.7495 - val_accuracy: 0.5965\n",
      "Epoch 117/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 827.4378 - accuracy: 0.5877 - val_loss: 1225.5814 - val_accuracy: 0.5220\n",
      "Epoch 118/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 404.8938 - accuracy: 0.6340 - val_loss: 1074.0762 - val_accuracy: 0.5846\n",
      "Epoch 119/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 935.3340 - accuracy: 0.5617 - val_loss: 1218.6703 - val_accuracy: 0.5699\n",
      "Epoch 120/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 698.1778 - accuracy: 0.5910 - val_loss: 355.5118 - val_accuracy: 0.6232\n",
      "Epoch 121/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 531.4974 - accuracy: 0.6140 - val_loss: 1235.6488 - val_accuracy: 0.5593\n",
      "Epoch 122/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1001.0703 - accuracy: 0.5713 - val_loss: 718.7318 - val_accuracy: 0.6005\n",
      "Epoch 123/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 940.1517 - accuracy: 0.5780 - val_loss: 899.3064 - val_accuracy: 0.5153\n",
      "Epoch 124/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1194.8179 - accuracy: 0.5653 - val_loss: 554.8831 - val_accuracy: 0.6005\n",
      "Epoch 125/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 540.0087 - accuracy: 0.6120 - val_loss: 499.9354 - val_accuracy: 0.6072\n",
      "Epoch 126/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1395.0759 - accuracy: 0.5743 - val_loss: 448.4974 - val_accuracy: 0.5712\n",
      "Epoch 127/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 942.8950 - accuracy: 0.5653 - val_loss: 598.8470 - val_accuracy: 0.5885\n",
      "Epoch 128/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 972.2708 - accuracy: 0.5877 - val_loss: 1783.6311 - val_accuracy: 0.4953\n",
      "Epoch 129/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1137.7439 - accuracy: 0.5677 - val_loss: 720.4799 - val_accuracy: 0.5087\n",
      "Epoch 130/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 837.9633 - accuracy: 0.6010 - val_loss: 884.9972 - val_accuracy: 0.5899\n",
      "Epoch 131/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 976.8817 - accuracy: 0.5753 - val_loss: 3414.1707 - val_accuracy: 0.6072\n",
      "Epoch 132/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 872.0814 - accuracy: 0.5877 - val_loss: 800.6902 - val_accuracy: 0.5126\n",
      "Epoch 133/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 791.2276 - accuracy: 0.5983 - val_loss: 1682.7692 - val_accuracy: 0.6232\n",
      "Epoch 134/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 898.3454 - accuracy: 0.6070 - val_loss: 360.3121 - val_accuracy: 0.6471\n",
      "Epoch 135/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1126.0011 - accuracy: 0.5680 - val_loss: 2440.3389 - val_accuracy: 0.5606\n",
      "Epoch 136/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1606.2461 - accuracy: 0.5540 - val_loss: 698.8971 - val_accuracy: 0.5273\n",
      "Epoch 137/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1129.9827 - accuracy: 0.5760 - val_loss: 2097.4573 - val_accuracy: 0.6125\n",
      "Epoch 138/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1091.5880 - accuracy: 0.5820 - val_loss: 685.5335 - val_accuracy: 0.6019\n",
      "Epoch 139/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 989.8720 - accuracy: 0.6007 - val_loss: 1307.0643 - val_accuracy: 0.4913\n",
      "Epoch 140/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 720.4525 - accuracy: 0.6063 - val_loss: 1414.3944 - val_accuracy: 0.6138\n",
      "Epoch 141/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1112.0170 - accuracy: 0.5740 - val_loss: 1405.9060 - val_accuracy: 0.5579\n",
      "Epoch 142/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1452.3813 - accuracy: 0.5803 - val_loss: 407.5196 - val_accuracy: 0.6871\n",
      "Epoch 143/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1377.8934 - accuracy: 0.5810 - val_loss: 1335.0994 - val_accuracy: 0.6338\n",
      "Epoch 144/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1362.5253 - accuracy: 0.5767 - val_loss: 1343.5094 - val_accuracy: 0.5699\n",
      "Epoch 145/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 902.8582 - accuracy: 0.6073 - val_loss: 706.7254 - val_accuracy: 0.5739\n",
      "Epoch 146/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1343.5637 - accuracy: 0.5800 - val_loss: 582.7308 - val_accuracy: 0.6272\n",
      "Epoch 147/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 934.3379 - accuracy: 0.6240 - val_loss: 972.7243 - val_accuracy: 0.5925\n",
      "Epoch 148/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1260.4841 - accuracy: 0.5670 - val_loss: 681.5820 - val_accuracy: 0.5846\n",
      "Epoch 149/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1128.6904 - accuracy: 0.5723 - val_loss: 1706.0249 - val_accuracy: 0.5326\n",
      "Epoch 150/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1301.2839 - accuracy: 0.6000 - val_loss: 449.0668 - val_accuracy: 0.6791\n",
      "Epoch 151/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1139.6592 - accuracy: 0.6103 - val_loss: 486.5169 - val_accuracy: 0.6431\n",
      "Epoch 152/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1788.6055 - accuracy: 0.5773 - val_loss: 2420.0581 - val_accuracy: 0.5832\n",
      "Epoch 153/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1567.1510 - accuracy: 0.5720 - val_loss: 2449.8569 - val_accuracy: 0.6178\n",
      "Epoch 154/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 1107.6150 - accuracy: 0.5963 - val_loss: 1162.3051 - val_accuracy: 0.5672\n",
      "Epoch 155/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1444.8713 - accuracy: 0.5773 - val_loss: 1225.3768 - val_accuracy: 0.5859\n",
      "Epoch 156/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1143.0435 - accuracy: 0.5977 - val_loss: 1542.2584 - val_accuracy: 0.6045\n",
      "Epoch 157/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1450.5439 - accuracy: 0.5900 - val_loss: 1549.4563 - val_accuracy: 0.5220\n",
      "Epoch 158/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1582.2853 - accuracy: 0.5690 - val_loss: 701.7418 - val_accuracy: 0.6165\n",
      "Epoch 159/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1733.3727 - accuracy: 0.5887 - val_loss: 1196.5505 - val_accuracy: 0.5619\n",
      "Epoch 160/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 944.0500 - accuracy: 0.6180 - val_loss: 2080.3333 - val_accuracy: 0.4980\n",
      "Epoch 161/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1632.9578 - accuracy: 0.5930 - val_loss: 1179.7504 - val_accuracy: 0.5859\n",
      "Epoch 162/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 833.6633 - accuracy: 0.6463 - val_loss: 345.3150 - val_accuracy: 0.7230\n",
      "Epoch 163/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1587.6788 - accuracy: 0.6050 - val_loss: 3501.4893 - val_accuracy: 0.4740\n",
      "Epoch 164/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1150.1788 - accuracy: 0.6103 - val_loss: 3713.6680 - val_accuracy: 0.5526\n",
      "Epoch 165/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1482.8643 - accuracy: 0.6120 - val_loss: 895.7668 - val_accuracy: 0.5992\n",
      "Epoch 166/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 933.3152 - accuracy: 0.6437 - val_loss: 767.1155 - val_accuracy: 0.6112\n",
      "Epoch 167/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1536.5300 - accuracy: 0.6033 - val_loss: 816.7687 - val_accuracy: 0.6192\n",
      "Epoch 168/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 2063.0742 - accuracy: 0.5697 - val_loss: 1284.5284 - val_accuracy: 0.5752\n",
      "Epoch 169/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1423.1918 - accuracy: 0.6043 - val_loss: 501.6525 - val_accuracy: 0.6924\n",
      "Epoch 170/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1911.8035 - accuracy: 0.5737 - val_loss: 4757.7378 - val_accuracy: 0.5087\n",
      "Epoch 171/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 1376.1815 - accuracy: 0.6303 - val_loss: 2816.3767 - val_accuracy: 0.4647\n",
      "Epoch 172/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 1799.3154 - accuracy: 0.5840 - val_loss: 659.4560 - val_accuracy: 0.6498\n",
      "Epoch 173/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1281.7719 - accuracy: 0.6140 - val_loss: 1078.6520 - val_accuracy: 0.5659\n",
      "Epoch 174/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1902.7590 - accuracy: 0.5947 - val_loss: 832.1339 - val_accuracy: 0.6272\n",
      "Epoch 175/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1194.1670 - accuracy: 0.5940 - val_loss: 949.3344 - val_accuracy: 0.6045\n",
      "Epoch 176/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1377.1390 - accuracy: 0.6000 - val_loss: 2675.9138 - val_accuracy: 0.6391\n",
      "Epoch 177/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1948.9412 - accuracy: 0.5847 - val_loss: 1663.3688 - val_accuracy: 0.5593\n",
      "Epoch 178/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1315.8173 - accuracy: 0.5870 - val_loss: 648.9591 - val_accuracy: 0.6338\n",
      "Epoch 179/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1832.0721 - accuracy: 0.5950 - val_loss: 1352.8279 - val_accuracy: 0.5885\n",
      "Epoch 180/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 2342.5996 - accuracy: 0.5777 - val_loss: 830.7712 - val_accuracy: 0.6485\n",
      "Epoch 181/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 2547.8096 - accuracy: 0.5857 - val_loss: 1038.6598 - val_accuracy: 0.6112\n",
      "Epoch 182/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1349.7000 - accuracy: 0.6193 - val_loss: 1038.6831 - val_accuracy: 0.5726\n",
      "Epoch 183/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 2110.2654 - accuracy: 0.5790 - val_loss: 1503.5405 - val_accuracy: 0.5273\n",
      "Epoch 184/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 2747.4946 - accuracy: 0.5797 - val_loss: 3923.0222 - val_accuracy: 0.6538\n",
      "Epoch 185/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1858.4945 - accuracy: 0.6113 - val_loss: 843.1487 - val_accuracy: 0.6671\n",
      "Epoch 186/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 2115.9651 - accuracy: 0.5923 - val_loss: 2210.7800 - val_accuracy: 0.5672\n",
      "Epoch 187/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 2032.8138 - accuracy: 0.5900 - val_loss: 4356.9062 - val_accuracy: 0.5712\n",
      "Epoch 188/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1646.1912 - accuracy: 0.6277 - val_loss: 872.8007 - val_accuracy: 0.6005\n",
      "Epoch 189/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 2946.7859 - accuracy: 0.5860 - val_loss: 1750.0668 - val_accuracy: 0.6338\n",
      "Epoch 190/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 2000.8787 - accuracy: 0.6207 - val_loss: 1394.3988 - val_accuracy: 0.5726\n",
      "Epoch 191/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 2116.7371 - accuracy: 0.5910 - val_loss: 2120.8750 - val_accuracy: 0.5353\n",
      "Epoch 192/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 1750.9458 - accuracy: 0.5927 - val_loss: 1021.7918 - val_accuracy: 0.5859\n",
      "Epoch 193/200\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 2728.6304 - accuracy: 0.5760 - val_loss: 2880.6287 - val_accuracy: 0.5593\n",
      "Epoch 194/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 2162.8508 - accuracy: 0.5943 - val_loss: 1130.8397 - val_accuracy: 0.6445\n",
      "Epoch 195/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1932.9158 - accuracy: 0.6277 - val_loss: 2900.2249 - val_accuracy: 0.5166\n",
      "Epoch 196/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 3744.0066 - accuracy: 0.5610 - val_loss: 1324.6471 - val_accuracy: 0.6352\n",
      "Epoch 197/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 2243.5386 - accuracy: 0.6023 - val_loss: 1663.1687 - val_accuracy: 0.5766\n",
      "Epoch 198/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 2681.5542 - accuracy: 0.5957 - val_loss: 6157.4570 - val_accuracy: 0.4514\n",
      "Epoch 199/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 3214.8843 - accuracy: 0.5693 - val_loss: 6981.3120 - val_accuracy: 0.4887\n",
      "Epoch 200/200\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 2546.7905 - accuracy: 0.5913 - val_loss: 3809.8164 - val_accuracy: 0.6405\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "#estimator = KerasClassifier(model=model, epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train, epochs=200, validation_data=(x_test, y_test)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 2ms/step\n",
      "[[0.9985868 ]\n",
      " [0.67792356]\n",
      " [0.27271444]\n",
      " ...\n",
      " [0.9334992 ]\n",
      " [0.86457944]\n",
      " [0.00753336]]\n",
      "(2501, 1)\n"
     ]
    }
   ],
   "source": [
    "prob_output = model.predict(kaggle_test)\n",
    "print(prob_output)\n",
    "print(prob_output.shape)\n",
    "#arr = prob_output.reshape(1,2501)\n",
    "df = pd.DataFrame(data=prob_output, columns=['PredictedProbability'])\n",
    "df['MoleculeId'] = df.index + 1\n",
    "df.head()\n",
    "df.to_csv('submissionDL.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
